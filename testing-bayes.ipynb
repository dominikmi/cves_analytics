{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries Import \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pgmpy.estimators import HillClimbSearch, BicScore\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "import networkx as nx\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "from pgmpy.inference import VariableElimination\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')  # To ignore warnings during CPD learning\n",
    "\n",
    "\n",
    "# Combining dataframes (rbind equivalent)\n",
    "all_df = pd.read_csv(\"output/cves_epss_kevs_cwe_enriched-2025-03-06.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107436, 36)\n"
     ]
    }
   ],
   "source": [
    "print(all_df.shape)   # Dimensions of the combined dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by cve_id and Checking Unique Values in Each Column\n",
    "grouped_df = all_df.groupby('cve_id').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for Identical Values in All Columns\n",
    "grouped_columns = grouped_df.iloc[:, 1:]  # Exclude the first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputation of Missing Values\n",
    "all_imp = all_df.groupby('cve_id').apply(lambda group: group.fillna(method='ffill').fillna(method='bfill'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categorical columns to encode\n",
    "categorical_columns = ['product', 'vulnerability_name', 'short_description', 'required_action', 'cwe', \n",
    "                       'vector', 'complexity', 'severity', 'vendor_project', 'cve_id', 'date_added', \n",
    "                       'due_date', 'pub_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encoding for Categorical Variables\n",
    "all_num_omitted = all_imp.copy()\n",
    "\n",
    "# List of categorical columns to encode\n",
    "categorical_columns = ['product', 'vulnerability_name', 'short_description', 'required_action', 'cwe', \n",
    "                       'vector', 'complexity', 'severity', 'vendor_project', 'cve_id', 'date_added', \n",
    "                       'due_date', 'pub_date']\n",
    "\n",
    "# Encode each categorical column\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    all_num_omitted[col] = le.fit_transform(all_num_omitted[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikey/HomeWorks/homelab-repos/cves_analytics/.venv/lib/python3.12/site-packages/pgmpy/factors/base.py:80: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"\"\"\n",
      "/Users/mikey/HomeWorks/homelab-repos/cves_analytics/.venv/lib/python3.12/site-packages/pgmpy/extern/tabulate.py:151: SyntaxWarning: invalid escape sequence '\\h'\n",
      "  return \"\\\\begin{tabular}{\" + tabular_columns_fmt + \"}\\n\\hline\"\n",
      "/Users/mikey/HomeWorks/homelab-repos/cves_analytics/.venv/lib/python3.12/site-packages/pgmpy/extern/tabulate.py:256: SyntaxWarning: invalid escape sequence '\\['\n",
      "  _invisible_codes = re.compile(\"\\x1b\\[\\d*m\")  # ANSI color codes\n",
      "/Users/mikey/HomeWorks/homelab-repos/cves_analytics/.venv/lib/python3.12/site-packages/pgmpy/extern/tabulate.py:257: SyntaxWarning: invalid escape sequence '\\['\n",
      "  _invisible_codes_bytes = re.compile(b\"\\x1b\\[\\d*m\")  # ANSI color codes\n",
      "/Users/mikey/HomeWorks/homelab-repos/cves_analytics/.venv/lib/python3.12/site-packages/pgmpy/models/MarkovNetwork.py:611: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  \"\"\"\n",
      "/Users/mikey/HomeWorks/homelab-repos/cves_analytics/.venv/lib/python3.12/site-packages/pgmpy/models/MarkovNetwork.py:725: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"\"\"\n",
      "/Users/mikey/HomeWorks/homelab-repos/cves_analytics/.venv/lib/python3.12/site-packages/pgmpy/models/FactorGraph.py:404: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"\"\"\n",
      "/Users/mikey/HomeWorks/homelab-repos/cves_analytics/.venv/lib/python3.12/site-packages/pgmpy/models/SEM.py:624: SyntaxWarning: invalid escape sequence '\\g'\n",
      "  \"\"\"\n",
      "/Users/mikey/HomeWorks/homelab-repos/cves_analytics/.venv/lib/python3.12/site-packages/pgmpy/inference/ExactInference.py:763: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"\"\"\n",
      "/Users/mikey/HomeWorks/homelab-repos/cves_analytics/.venv/lib/python3.12/site-packages/pgmpy/inference/mplp.py:101: SyntaxWarning: invalid escape sequence '\\{'\n",
      "  \"\"\"\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/exploring-cybersecurity-risk-via-2022-cisa-vulne/2022-12-09-enriched.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# To ignore warnings during CPD learning\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Reading CSV files\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m df1209 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/exploring-cybersecurity-risk-via-2022-cisa-vulne/2022-12-09-enriched.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m df0704 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/exploring-cybersecurity-risk-via-2022-cisa-vulne/2022-07-04-enriched.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m df0627 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/exploring-cybersecurity-risk-via-2022-cisa-vulne/2022-06-27-enriched.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/HomeWorks/homelab-repos/cves_analytics/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HomeWorks/homelab-repos/cves_analytics/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/HomeWorks/homelab-repos/cves_analytics/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HomeWorks/homelab-repos/cves_analytics/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/HomeWorks/homelab-repos/cves_analytics/.venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/exploring-cybersecurity-risk-via-2022-cisa-vulne/2022-12-09-enriched.csv'"
     ]
    }
   ],
   "source": [
    "# Libraries Import \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pgmpy.estimators import HillClimbSearch, BicScore\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "import networkx as nx\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "from pgmpy.inference import VariableElimination\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')  # To ignore warnings during CPD learning\n",
    "\n",
    "\n",
    "# Combining dataframes (rbind equivalent)\n",
    "all_df = pd.read(\"output/cves\")\n",
    "\n",
    "# Inspecting the data\n",
    "print(all_df.head())  # First 6 rows\n",
    "\n",
    "print(all_df.shape)   # Dimensions of the combined dataframe\n",
    "\n",
    "# Checking for missing values\n",
    "print(all_df.isna().sum())\n",
    "\n",
    "# Dropping the 'notes' column\n",
    "all_df = all_df.drop(columns=['notes'])\n",
    "\n",
    "# Rechecking missing values\n",
    "print(all_df.isna().sum())\n",
    "\n",
    "# Data structure summary\n",
    "print(all_df.info())\n",
    "\n",
    "# Summary statistics for numeric columns\n",
    "print(all_df.describe())\n",
    "\n",
    "# Grouping by cve_id and Checking Unique Values in Each Column\n",
    "grouped_df = all_df.groupby('cve_id').nunique()\n",
    "\n",
    "\n",
    "# Checking for Identical Values in All Columns\n",
    "grouped_columns = grouped_df.iloc[:, 1:]  # Exclude the first column\n",
    "are_columns_identical = (grouped_columns == grouped_columns.iloc[:, 0]).all().all()\n",
    "print(are_columns_identical)\n",
    "\n",
    "\n",
    "# Checking Which Columns Have Different Values\n",
    "different_columns = grouped_columns.columns[~(grouped_columns == grouped_columns.iloc[:, 0]).all()]\n",
    "print(different_columns)\n",
    "\n",
    "#Imputation of Missing Values\n",
    "all_imp = all_df.groupby('cve_id').apply(lambda group: group.fillna(method='ffill').fillna(method='bfill'))\n",
    "\n",
    "\n",
    "# Rechecking Missing Values After Imputation\n",
    "all_imp.isna().sum()\n",
    "\n",
    "\n",
    "#Label Encoding for Categorical Variables\n",
    "all_num_omitted = all_imp.copy()\n",
    "\n",
    "# List of categorical columns to encode\n",
    "categorical_columns = ['product', 'vulnerability_name', 'short_description', 'required_action', 'cwe', \n",
    "                       'vector', 'complexity', 'severity', 'vendor_project', 'cve_id', 'date_added', \n",
    "                       'due_date', 'pub_date']\n",
    "\n",
    "# Encode each categorical column\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    all_num_omitted[col] = le.fit_transform(all_num_omitted[col].astype(str))\n",
    "\n",
    "\n",
    "# Removing Missing Values\n",
    "all_num_omitted = all_num_omitted.dropna()\n",
    "\n",
    "## Correlation Analysis\n",
    "\n",
    "# Select relevant columns\n",
    "columns_of_interest = ['severity', 'complexity', 'vector', 'cvss']\n",
    "subset_df = all_num_omitted[columns_of_interest]\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = subset_df.corr()\n",
    "\n",
    "# Plot the correlation matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "\n",
    "# Correlation Matrix for All Numeric Variables\n",
    "correlation_matrix_all = all_num_omitted.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix_all, annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "\n",
    "# Scatter Plot: CVSS vs Severity\n",
    "sns.scatterplot(data=all_num_omitted, x='cvss', y='severity', marker='o', color='black')\n",
    "\n",
    "plt.xlabel(\"CVSS Score\")\n",
    "plt.ylabel(\"Severity\")\n",
    "plt.xticks(range(0, 11, 1))  # Breaks from 0 to 10\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "#  Imputing Missing Values for product and short_description\n",
    "all_imp['product'].fillna('fuel cms', inplace=True)\n",
    "all_imp['short_description'].fillna('na', inplace=True)\n",
    "\n",
    "\n",
    "# Imputing Missing pub_date Based on cve_id\n",
    "all_imp['pub_date'] = all_imp.groupby('cve_id')['pub_date'].transform(lambda x: x.fillna(x.max()))\n",
    "\n",
    "\n",
    "# Checking for NA Values in cvss and severity\n",
    "same_na_rows = (all_imp['cvss'].isna() == all_imp['severity'].isna()).all()\n",
    "print(same_na_rows)\n",
    "\n",
    "# Removing Remaining Rows with Missing Values\n",
    "all_num_clean = all_imp.copy()\n",
    "\n",
    "# List of categorical columns\n",
    "categorical_columns = ['product', 'vulnerability_name', 'short_description', 'required_action', \n",
    "                       'cwe', 'vector', 'complexity', 'severity', 'vendor_project', 'cve_id', \n",
    "                       'date_added', 'due_date', 'pub_date']\n",
    "\n",
    "# Apply label encoding\n",
    "le = LabelEncoder()\n",
    "for col in categorical_columns:\n",
    "    all_num_clean[col] = le.fit_transform(all_num_clean[col].astype(str))\n",
    "\n",
    "\n",
    "# Final DataFrame Structure\n",
    "all_num_clean.info()\n",
    "\n",
    "\n",
    "# Correlation Matrix for all_num_clean\n",
    "correlation_matrix2 = all_num_clean.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix2, annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "\n",
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "# Analysis of Vulnerability Severity Levels\n",
    "severity_counts = all_imp['severity'].value_counts()\n",
    "\n",
    "plt.pie(severity_counts, labels=severity_counts.index, autopct='%1.1f%%')\n",
    "plt.title(\"Distribution of Vulnerability Severity Levels\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Vulnerability Trends Over Time\n",
    "all_imp['date_added'] = pd.to_datetime(all_imp['date_added']).dt.to_period('M')\n",
    "\n",
    "vuln_counts = all_imp['date_added'].value_counts().sort_index()\n",
    "\n",
    "vuln_counts.plot(kind='line', title='Trends in Vulnerability Counts')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Vulnerabilities')\n",
    "plt.show()\n",
    "\n",
    "# Trends in Vulnerability Counts by Severity\n",
    "severity_counts = all_imp.groupby(['date_added', 'severity']).size().unstack()\n",
    "\n",
    "severity_counts.plot(kind='line', title='Trends in Vulnerability Counts by Severity')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Vulnerabilities')\n",
    "plt.show()\n",
    "\n",
    "# Proportion of Vulnerabilities with Due Dates Met\n",
    "proportion_due_dates_met = all_imp['due_date'].notna().sum() / len(all_imp) * 100\n",
    "print(f\"Proportion of vulnerabilities with due dates met: {proportion_due_dates_met:.2f}%\")\n",
    "\n",
    "# Distribution of Vulnerabilities by Vector\n",
    "vulnerabilities_by_vector = all_imp['vector'].value_counts()\n",
    "\n",
    "plt.pie(vulnerabilities_by_vector, labels=vulnerabilities_by_vector.index, autopct='%1.1f%%')\n",
    "plt.title(\"Distribution of Vulnerabilities by Vector\")\n",
    "plt.show()\n",
    "\n",
    "# Distribution of Vulnerabilities by Complexity Level\n",
    "complexity_counts = all_imp['complexity'].value_counts()\n",
    "\n",
    "complexity_counts.plot(kind='bar', title='Distribution of Vulnerabilities by Complexity Level')\n",
    "plt.xlabel('Complexity Level')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Top Vendors with the Highest Number of Vulnerabilities\n",
    "top_vendors = all_imp['vendor_project'].value_counts().nlargest(10)\n",
    "\n",
    "top_vendors.plot(kind='bar', title='Top 10 Vendors with the Highest Number of Vulnerabilities')\n",
    "plt.xlabel('Vendor')\n",
    "plt.ylabel('Total Vulnerabilities')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Top Products with the Highest Number of Vulnerabilities\n",
    "top_products = all_imp['product'].value_counts().nlargest(10)\n",
    "\n",
    "top_products.plot(kind='bar', title='Top 10 Products with the Highest Number of Vulnerabilities')\n",
    "plt.xlabel('Product')\n",
    "plt.ylabel('Total Vulnerabilities')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Most Common CWE Categories among Vulnerabilities\n",
    "common_cwe = all_imp['cwe'].value_counts().nlargest(10)\n",
    "\n",
    "common_cwe.plot(kind='bar', title='Most Common CWE Categories among Vulnerabilities', color='orange')\n",
    "plt.xlabel('CWE Category')\n",
    "plt.ylabel('Total Vulnerabilities')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Analysis on Patching Speed\n",
    "all_imp['patching_time'] = (pd.to_datetime(all_imp['due_date']) - pd.to_datetime(all_imp['pub_date'])).dt.days\n",
    "\n",
    "print(all_imp['patching_time'].describe())\n",
    "\n",
    "all_imp['patching_time'].hist(bins=20)\n",
    "plt.xlabel('Patching Time (Days)')\n",
    "plt.title('Distribution of Patching Time')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Severity vs Patching Time\n",
    "plt.scatter(all_num_clean['severity'], all_imp['patching_time'])\n",
    "plt.xlabel('Severity')\n",
    "plt.ylabel('Patching Time (Days)')\n",
    "plt.title('Severity vs. Patching Time')\n",
    "plt.show()\n",
    "\n",
    "correlation = all_num_clean['severity'].corr(all_imp['patching_time'])\n",
    "print(f\"Correlation between Severity and Patching Time: {correlation:.4f}\")\n",
    "\n",
    "## Bayesian Network Model\n",
    "\n",
    "# Learn the structure of the Bayesian network using Hill Climbing\n",
    "hc = HillClimbSearch(all_num_clean)\n",
    "model = hc.estimate(scoring_method=BicScore(all_num_clean))\n",
    "\n",
    "# Convert model to a Bayesian Network\n",
    "bn_model = BayesianNetwork(model.edges())\n",
    "\n",
    "# Print out the learned structure (edges of the network)\n",
    "print(bn_model.edges())\n",
    "\n",
    "# Visualize the Bayesian Network using networkx and matplotlib\n",
    "G = nx.DiGraph(bn_model.edges())\n",
    "pos = nx.spring_layout(G)  # For better layout\n",
    "plt.figure(figsize=(12, 8))\n",
    "nx.draw(G, pos, with_labels=True, node_size=3000, node_color=\"skyblue\", font_size=10, font_weight='bold', arrows=True)\n",
    "plt.title(\"Bayesian Network Structure\")\n",
    "plt.show()\n",
    "\n",
    "## Model Validation \n",
    "\n",
    "# 1. Parameter Learning and Log-Likelihood\n",
    "\n",
    "# Learn the CPDs (parameters) using Maximum Likelihood Estimation (MLE)\n",
    "bn_model.fit(all_num_clean, estimator=MaximumLikelihoodEstimator)\n",
    "\n",
    "# Check the learned CPDs\n",
    "for cpd in bn_model.get_cpds():\n",
    "    print(cpd)\n",
    "\n",
    "# Calculate the log-likelihood of the data given the learned network\n",
    "log_likelihood = bn_model.log_likelihood(all_num_clean)\n",
    "print(f\"Log-Likelihood of the model: {log_likelihood}\")\n",
    "\n",
    "# 2. Inference Queries\n",
    "\n",
    "# Perform inference on the Bayesian Network\n",
    "inference = VariableElimination(bn_model)\n",
    "\n",
    "# Example 1: Query the probability distribution of 'severity' given a specific CVSS score and complexity level\n",
    "query_result = inference.query(variables=['severity'], evidence={'cvss': 9, 'complexity': 1})\n",
    "\n",
    "print(query_result)\n",
    "\n",
    "# Example 2: Query the probability distribution of 'cvss' given a specific vector and severity level\n",
    "query_result2 = inference.query(variables=['cvss'], evidence={'vector': 2, 'severity': 1})\n",
    "\n",
    "print(query_result2)\n",
    "\n",
    "\n",
    "# 3. Cross-Validation Using Log-Likelihood\n",
    "\n",
    "# Set up KFold cross-validation (e.g., 5 folds)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "log_likelihoods = []\n",
    "\n",
    "for train_index, test_index in kf.split(all_num_clean):\n",
    "    train_data = all_num_clean.iloc[train_index]\n",
    "    test_data = all_num_clean.iloc[test_index]\n",
    "    \n",
    "    # Create a new Bayesian Network for each fold\n",
    "    fold_model = BayesianNetwork(model.edges())\n",
    "    \n",
    "    # Fit the model using MLE\n",
    "    fold_model.fit(train_data, estimator=MaximumLikelihoodEstimator)\n",
    "    \n",
    "    # Calculate the log-likelihood on the test data\n",
    "    test_log_likelihood = fold_model.log_likelihood(test_data)\n",
    "    log_likelihoods.append(test_log_likelihood)\n",
    "    \n",
    "    print(f\"Log-Likelihood for this fold: {test_log_likelihood}\")\n",
    "\n",
    "# Calculate the average log-likelihood across all folds\n",
    "average_log_likelihood = sum(log_likelihoods) / len(log_likelihoods)\n",
    "print(f\"Average Log-Likelihood: {average_log_likelihood}\")\n",
    "\n",
    "# Tracking the individual log-likelihood scores across folds \n",
    "print(\"Log-Likelihoods for each fold: \", log_likelihoods)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
