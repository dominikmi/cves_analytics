{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import spacy\n",
    "import logging\n",
    "import os \n",
    "import re\n",
    "import json\n",
    "import datetime\n",
    "import gzip\n",
    "\n",
    "#Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"logs/app.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ExploitDB\n",
    "from pyExploitDb import PyExploitDb\n",
    "pEdb = PyExploitDb()\n",
    "pEdb.debug = False\n",
    "pEdb.openFile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and unzip NVD CVE data\n",
    "def download_nvd_cve_data(start_year, end_year, directory):\n",
    "    base_url = \"https://nvd.nist.gov/feeds/json/cve/1.1/nvdcve-1.1-{}.json.zip\"\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    for year in range(start_year, end_year + 1):\n",
    "        file_path = os.path.join(directory, f\"nvdcve-1.1-{year}.json.zip\")\n",
    "        if os.path.exists(file_path):\n",
    "            logger.info(f\"File {file_path} already exists, skipping download.\")\n",
    "            continue\n",
    "        \n",
    "        url = base_url.format(year)\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            with open(file_path, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "            logger.info(f\"Downloaded {file_path}\")\n",
    "        else:\n",
    "            logger.error(f\"Failed to download data for year {year}\")\n",
    "\n",
    "# unzip all found files in the directory\n",
    "def unzip_files(directory):\n",
    "    import zipfile\n",
    "    import os\n",
    "    \n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".zip\"):\n",
    "            file_path = os.path.join(directory, file)\n",
    "            with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(directory)\n",
    "                logger.info(f\"Unzipped {file_path}\")\n",
    "                os.remove(file_path)\n",
    "\n",
    "# Load NVD CVE data into a DataFrame\n",
    "def load_nvd_cve_data(directory):\n",
    "    data = []\n",
    "    cves_list = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".json\"):\n",
    "            file_path = os.path.join(directory, file)\n",
    "            with open(file_path, 'r') as file:\n",
    "                data = json.load(file)\n",
    "                logger.info(f\"Loaded {file_path}\")\n",
    "                for index, item in enumerate(data.get(\"CVE_Items\", [])):\n",
    "                    cve = (\n",
    "                        item.get(\"cve\", {}).get(\"CVE_data_meta\", {}).get(\"ID\", \"\"), \n",
    "                        item.get(\"cve\", {}).get(\"description\", {}).get(\"description_data\", [{}])[0].get(\"value\", \"\"),\n",
    "                        item.get(\"publishedDate\", \"\"),\n",
    "                        item.get(\"lastModifiedDate\", \"\"),\n",
    "                        item.get(\"impact\", {}).get(\"baseMetricV3\", {}).get(\"cvssV3\", {}).get(\"version\", item.get(\"impact\", {}).get(\"baseMetricV2\", {}).get(\"cvssV2\", {}).get(\"version\", \"\")),\n",
    "                        item.get(\"impact\", {}).get(\"baseMetricV3\", {}).get(\"cvssV3\", {}).get(\"vectorString\", item.get(\"impact\", {}).get(\"baseMetricV2\", {}).get(\"cvssV2\", {}).get(\"vectorString\", \"\")),\n",
    "                        item.get(\"impact\", {}).get(\"baseMetricV3\", {}).get(\"cvssV3\", {}).get(\"attackVector\", item.get(\"impact\", {}).get(\"baseMetricV2\", {}).get(\"cvssV2\", {}).get(\"accessVector\", \"\")),\n",
    "                        item.get(\"impact\", {}).get(\"baseMetricV3\", {}).get(\"cvssV3\", {}).get(\"attackComplexity\", item.get(\"impact\", {}).get(\"baseMetricV2\", {}).get(\"cvssV2\", {}).get(\"accessComplexity\", \"\")),\n",
    "                        item.get(\"impact\", {}).get(\"baseMetricV3\", {}).get(\"cvssV3\", {}).get(\"privilegesRequired\", item.get(\"impact\", {}).get(\"baseMetricV2\", {}).get(\"cvssV2\", {}).get(\"authentication\", \"\")),\n",
    "                        item.get(\"impact\", {}).get(\"baseMetricV3\", {}).get(\"cvssV3\", {}).get(\"userInteraction\", item.get(\"impact\", {}).get(\"baseMetricV2\", {}).get(\"cvssV2\", {}).get(\"userInteraction\", \"\")),\n",
    "                        item.get(\"impact\", {}).get(\"baseMetricV3\", {}).get(\"cvssV3\", {}).get(\"baseScore\", item.get(\"impact\", {}).get(\"baseMetricV2\", {}).get(\"cvssV2\", {}).get(\"baseScore\", \"\")),\n",
    "                        item.get(\"impact\", {}).get(\"baseMetricV3\", {}).get(\"cvssV3\", {}).get(\"baseSeverity\", item.get(\"impact\", {}).get(\"baseMetricV2\", {}).get(\"severity\", \"\")),\n",
    "                        item.get(\"impact\", {}).get(\"baseMetricV3\", {}).get(\"exploitabilityScore\", item.get(\"impact\", {}).get(\"baseMetricV2\", {}).get(\"exploitabilityScore\", \"\")),\n",
    "                        item.get(\"impact\", {}).get(\"baseMetricV3\", {}).get(\"impactScore\", item.get(\"impact\", {}).get(\"baseMetricV2\", {}).get(\"impactScore\", \"\")),\n",
    "                        item.get(\"impact\", {}).get(\"baseMetricV3\", {}).get(\"scope\", item.get(\"impact\", {}).get(\"baseMetricV2\", {}).get(\"scope\", \"\")),\n",
    "                        item.get(\"impact\", {}).get(\"baseMetricV3\", {}).get(\"confidentialityImpact\", item.get(\"impact\", {}).get(\"baseMetricV2\", {}).get(\"confidentialityImpact\", \"\")),\n",
    "                        item.get(\"impact\", {}).get(\"baseMetricV3\", {}).get(\"integrityImpact\", item.get(\"impact\", {}).get(\"baseMetricV2\", {}).get(\"integrityImpact\", \"\")),\n",
    "                        item.get(\"impact\", {}).get(\"baseMetricV3\", {}).get(\"availabilityImpact\", item.get(\"impact\", {}).get(\"baseMetricV2\", {}).get(\"availabilityImpact\", \"\")),\n",
    "                    )\n",
    "                    cves_list.append(cve)\n",
    "\n",
    "    cves_df = pd.DataFrame(cves_list, columns=[\"cve_id\", \"description\", \"published_date\", \"last_modified_date\", \"cvss_version\", \"cvss_vector\", \"attack_vector\", \"attack_complexity\", \"privileges_required\", \"user_interaction\", \"base_score\", \"base_severity\", \"exploitability_score\", \"impact_score\", \"scope\", \"confidentiality_impact\", \"integrity_impact\", \"availability_impact\"])\n",
    "    return cves_df\n",
    "\n",
    "# Download EPSS scores and ungzip them\n",
    "def download_epss_scores(date, directory):\n",
    "    # Download EPSS scores for a given date -1 day\n",
    "    yesterday = datetime.datetime.strptime(date, \"%Y-%m-%d\") - datetime.timedelta(days=1)\n",
    "    yesterday = yesterday.strftime(\"%Y-%m-%d\")\n",
    "    file_path = os.path.join(directory, f\"epss_scores-{yesterday}.csv.gz\")\n",
    "    try:\n",
    "        if not os.path.exists(file_path):\n",
    "            logger.info(f\"Downloading EPSS scores for date {yesterday}\")\n",
    "            url = f\"https://epss.cyentia.com/epss_scores-{yesterday}.csv.gz\"\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                with open(file_path, 'wb') as file:\n",
    "                    file.write(response.content)\n",
    "                logger.info(f\"Downloaded {file_path}\")\n",
    "        else:\n",
    "            logger.info(f\"File {file_path} already exists, skipping download.\")\n",
    "\n",
    "        logger.info(f\"Unzipping {file_path}\")\n",
    "        with gzip.open(file_path, 'rb') as file_in:\n",
    "            with open(file_path.replace(\".gz\", \"\"), 'wb') as file_out:\n",
    "                file_out.write(file_in.read())\n",
    "            return file_path.replace(\".gz\", \"\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to download EPSS scores for date {date}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Check on exploitability against exploitdb data\n",
    "def get_exploitdb_data(cve_id):\n",
    "    \"\"\"\n",
    "    Get the ExploitDB data for a given CVE ID.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Searching ExploitDB data for {cve_id}\")\n",
    "        exploitdb_data = pEdb.searchCve(cve_id)\n",
    "        if exploitdb_data:\n",
    "            return pd.Series({\n",
    "                \"exploitdb_id\": exploitdb_data.get(\"id\", \"\"),\n",
    "                \"description\": exploitdb_data.get(\"description\", \"\"),\n",
    "                \"date\": exploitdb_data.get(\"date\", \"\"),\n",
    "                \"date_updated\": exploitdb_data.get(\"date_updated\", \"\"),\n",
    "                \"author\": exploitdb_data.get(\"author\", \"\"),\n",
    "                \"type\": exploitdb_data.get(\"type\", \"\"),\n",
    "                \"platform\": exploitdb_data.get(\"platform\", \"\"),\n",
    "                \"port\": exploitdb_data.get(\"port\", \"\"),\n",
    "                \"url\": exploitdb_data.get(\"url\", \"\")\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting ExploitDB data for {cve_id}: {e}\")\n",
    "        return pd.Series({\n",
    "            \"exploitdb_id\": None,\n",
    "            \"description\": None,\n",
    "            \"date\": None,\n",
    "            \"author\": None,\n",
    "            \"type\": None,\n",
    "            \"platform\": None,\n",
    "            \"port\": None,\n",
    "            \"url\": None\n",
    "        })\n",
    "\n",
    "# Download KEV data  \n",
    "def download_known_exploited_vulnerabilities():\n",
    "    url = \"https://www.cisa.gov/sites/default/files/csv/known_exploited_vulnerabilities.csv\"\n",
    "    \n",
    "    # Download the file and return a DataFrame\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        file_path = os.path.join(\"data/download\", \"known_exploited_vulnerabilities.csv\")\n",
    "        with open(file_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        logger.info(f\"Downloaded known exploited vulnerabilities to {file_path}\")\n",
    "        return pd.read_csv(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading known exploited vulnerabilities: {e}\")\n",
    "        return None\n",
    "    \n",
    "# Enrichment with CISAGOV data\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "token = os.getenv('GH_TOKEN')\n",
    "header = {'Authorization': f'token {token}'}\n",
    "url = f\"https://api.github.com/repos/cisagov/vulnrichment\"\n",
    "output = requests.get(url,headers=header)\n",
    "download_dir = \"data/download/CISAGOV\"\n",
    "\n",
    "# function which returns a position in the \"metrics\" list where the \"name\" key matches the given value\n",
    "def get_metric_position_of_other(metrics_list):\n",
    "    for i, metric in enumerate(metrics_list):\n",
    "        if \"other\" in metric:\n",
    "            return i\n",
    "    return None\n",
    "\n",
    "# make output flattened\n",
    "def flatten_vulnrichment_output(vulnrichment_output):\n",
    "    flattened_output = {}\n",
    "    for keyval in vulnrichment_output:\n",
    "        if isinstance(keyval, dict):\n",
    "            for k, v in keyval.items():\n",
    "                flattened_output[k] = v\n",
    "        else:\n",
    "            return None\n",
    "    return flattened_output\n",
    "\n",
    "def cve_vulnrichment(cve_id):\n",
    "    parts = cve_id.split(\"-\")\n",
    "    year = parts[1]  # Example: \"2021\"\n",
    "    number = int(parts[2])  # Example: \"3493\" â†’ 3493\n",
    "    thousands_group = f\"{(number // 1000)}xxx\"  # Calculate folder name, e.g., 3xxx\n",
    "\n",
    "    # Construct URL for the JSON file\n",
    "    file_path = f\"{year}/{thousands_group}/{cve_id}.json\"\n",
    "    file_url = f\"{url}/contents/{file_path}\"\n",
    "\n",
    "    try:\n",
    "        # Get the metadata for the file\n",
    "        metadata_output = requests.get(file_url,headers=header)\n",
    "        metadata_output.raise_for_status()\n",
    "        metadata = metadata_output.json()\n",
    "        download_url = metadata[\"download_url\"]\n",
    "\n",
    "        # check if the file already exists\n",
    "        downloaded_file = os.path.join(download_dir, f\"{cve_id}.json\")\n",
    "        if os.path.exists(downloaded_file):\n",
    "            logger.info(f\"File {downloaded_file} already exists, skipping download.\")\n",
    "            # read the file and return the options\n",
    "            with open(downloaded_file, \"r\") as file:\n",
    "                cve = json.load(file)\n",
    "                if cve.get(\"cveMetadata\", {}).get(\"state\") != \"REJECTED\":\n",
    "                    adp_list = cve.get(\"containers\", []).get(\"adp\", [])\n",
    "                    for i, item in enumerate(adp_list):\n",
    "                        if \"CISA ADP Vulnrichment\" in item.get(\"title\"):\n",
    "                            adp_position = i\n",
    "                    other = adp_list[adp_position].get(\"metrics\", {})\n",
    "                    position = get_metric_position_of_other(adp_list[adp_position].get(\"metrics\", {}))\n",
    "                    logger.info(f\"Found positions: {adp_position}, {position}\")\n",
    "                    return other[position].get(\"other\").get(\"content\").get(\"options\")\n",
    "                else:\n",
    "                    return [{\"Exploitation\": None}, {\"Automatable\": None}, {\"Technical Impact\": None}]\n",
    "\n",
    "        # Downloading the JSON file\n",
    "        logger.info(f\"Download URL found, downloading: {download_url}\")\n",
    "        json_response = requests.get(download_url)\n",
    "        json_response.raise_for_status()\n",
    "        json_data = json_response.json()\n",
    "\n",
    "        # Create the download folder if it doesn't exist\n",
    "        os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "        # Save the file locally\n",
    "        local_file_path = os.path.join(download_dir, f\"{cve_id}.json\")\n",
    "        with open(local_file_path, \"w\") as f:\n",
    "            json.dump(json_data, f, indent=4)\n",
    "\n",
    "        logger.info(f\"Downloaded and saved {cve_id} to {local_file_path}\")\n",
    "        if json_data.get(\"cveMetadata\", {}).get(\"state\") != \"REJECTED\":\n",
    "            adp_list = json_data.get(\"containers\", []).get(\"adp\", [])\n",
    "            for i, item in enumerate(adp_list):\n",
    "                if \"CISA ADP Vulnrichment\" in item.get(\"title\"):\n",
    "                    adp_position = i\n",
    "            other = adp_list[adp_position].get(\"metrics\", {})\n",
    "            position = get_metric_position_of_other(adp_list[adp_position].get(\"metrics\", {}))\n",
    "            logger.info(f\"Found positions: {adp_position}, {position}\")\n",
    "            return other[position].get(\"other\").get(\"content\").get(\"options\")\n",
    "        else:\n",
    "            return [{\"Exploitation\": None}, {\"Automatable\": None}, {\"Technical Impact\": None}]\n",
    "    \n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        logger.error(f\"Error downloading {cve_id}: {e}\")\n",
    "        return [{\"Exploitation\": None}, {\"Automatable\": None}, {\"Technical Impact\": None}]\n",
    "\n",
    "# Update the row with the details from the vulnrichment output\n",
    "def update_row_with_details(row):\n",
    "    details = flatten_vulnrichment_output(cve_vulnrichment(row['cve_id']))  # Fetch details for the current row's cve_id\n",
    "    if not details:\n",
    "        return \n",
    "    for key, value in details.items():\n",
    "        row[key] = value  # Add each detail as a new column to the row\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_nvd_cve_data(2004, 2025, \"data/download\")\n",
    "unzip_files(\"data/download\")\n",
    "\n",
    "cves = load_nvd_cve_data(\"data/download\")\n",
    "# Sort by CVE ID\n",
    "cves = cves.sort_values(by=\"cve_id\")\n",
    "\n",
    "cves.to_csv(\"output/cves_2004-2025.csv\", index=False)\n",
    "today_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "epss_file = download_epss_scores(today_date, \"data/download\")\n",
    "epss_scores = pd.read_csv(epss_file, skiprows=1)\n",
    "cves_with_epss = pd.merge(cves,epss_scores, left_on=\"cve_id\", right_on=\"cve\", how=\"left\")\n",
    "cves_with_epss.drop(columns=[\"cve\"], inplace=True)\n",
    "cves_with_epss.to_csv(\"output/cves_with_epss_2004-2025.csv\", index=False)\n",
    "kevs = download_known_exploited_vulnerabilities()\n",
    "\n",
    "# simulate identified vulns outcome\n",
    "outcome_cves = cves_with_epss.sample(1000)\n",
    "outcome_cves.drop(columns=[\"scope\", \"confidentiality_impact\", \"integrity_impact\", \"availability_impact\"], inplace=True)\n",
    "outcome_cves = outcome_cves.apply(update_row_with_details, axis=1)\n",
    "outcome_cves.to_csv(\"output/outcome_cves_epss_enriched-20250106.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse cve descriptions to find relevant Categories and re-assess original CVSS impact\n",
    "(use spacy.io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
